{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW11_Deep1400_2 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QNjXfQ5kWd7l"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "05e4mKftC8BP"
      },
      "source": [
        "#@title Student Information\n",
        "#@markdown Enter the following info and run the cell:\n",
        "Name = \"Amin Fathi\" #@param {type:\"string\"}\n",
        "StudentNumber =  400722102#@param {type:\"integer\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf-jnHngag-m"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "برای پیاده سازی این سوال از لینک زیر استفاده شده است :\n",
        "https://github.com/prashil2792/Question-Answering-System-Deep-Learning/blob/master/Question%20Answering%20Memory%20Network.ipynb"
      ],
      "metadata": {
        "id": "94hKTMIzSHhq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJBzDr12K3bf"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0twGcAkFWiG"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import IPython\n",
        "from IPython.display import clear_output \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate\n",
        "from keras.layers import LSTM\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGw9iBLGU9Cu",
        "outputId": "adcf5079-6c08-427b-c293-2781b78489d7"
      },
      "source": [
        "!nvidia-smi # check if gpu mode is selected"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JqUZuEo8G_p"
      },
      "source": [
        "We will use a dataset consists of questions where a previously given single supporting fact, potentially amongst a set of other irrelevant facts, provides the answer. We first test one of the simplest cases of this, by asking for the location of a person, e.g. “$Mary$ $travelled$ $to$ $the$ $office.$ $Where$ $is$ $Mary?$”. It can be considered the\n",
        "simplest case of some real world QA datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsvVnfvfGnib"
      },
      "source": [
        "About the dataset: https://research.fb.com/downloads/babi/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OlahJ1OrKjd"
      },
      "source": [
        "Lets download the dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_dp3WT7FW8E"
      },
      "source": [
        "# 1. LSTM- Q&A\n",
        "\n",
        "This is a bonus section with extra score for those who coplete this section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "259V3MeC9G55"
      },
      "source": [
        "## 1.2 Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u_xDAfovXf7"
      },
      "source": [
        "Our model takes a discrete set of inputs $x_{1}, ..., x_{n}$ that are to be stored in the memory, a query $q$, and outputs an answer $a$. Each of the $x_{i}$, $q$, and $a$ contains symbols coming from a dictionary with $V$ words. The model writes all $x$ to the memory up to a fixed buffer size, and then finds a continuous representation for the $x$ and $q$. The continuous representation is then processed via multiple hops to\n",
        "output $a$. This allows backpropagation of the error signal through multiple memory accesses back to the input during training. The overall model is shown in the next figure. During training, all three embedding matrices $A, B$ and $C$, as well as $W$ are jointly learned by minimizing a standard cross-entropy loss between $aˆ$ and the true\n",
        "label $a$. Training is performed using stochastic gradient descent.\n",
        "\n",
        "\n",
        "Delve more deeply into the details: https://arxiv.org/pdf/1503.08895.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx-wpcdQJfpk"
      },
      "source": [
        "%%capture\n",
        "!wget https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
        "!tar -xvzf babi_tasks_1-20_v1-2.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBYgDigJanwz"
      },
      "source": [
        "challenges = [\n",
        "    'qa1_single-supporting-fact',\n",
        "    'qa2_two-supporting-facts',\n",
        "]\n",
        "train_file_path = f'/content/tasks_1-20_v1-2/en-10k/{challenges[0]}_train.txt'\n",
        "test_file_path = f'/content/tasks_1-20_v1-2/en-10k/{challenges[0]}_test.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCBfH4qrrKjL"
      },
      "source": [
        "def word_tokenizer(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WLJmevS-Dy6"
      },
      "source": [
        "According to the dataset (bAbi tasks), we need to prepare the data for training the model. With the next function we parse the dataset and manufactore it in desired way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzksSX8drKjP"
      },
      "source": [
        "def parse_stories(lines, only_supporting=False, tokenize = True):\n",
        "    '''Parse stories provided in the bAbi tasks format\n",
        "    If only_supporting is true, only the sentences\n",
        "    that support the answer are kept.\n",
        "    '''\n",
        "    data = []\n",
        "    story = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        nid, line = line.split(' ', 1)\n",
        "        nid = int(nid)\n",
        "        if nid == 1:\n",
        "            story = []\n",
        "        if '\\t' in line:\n",
        "            q, a, supporting = line.split('\\t')\n",
        "            if tokenize:\n",
        "                q = word_tokenizer(q)\n",
        "            substory = None\n",
        "            if only_supporting:\n",
        "                # Only select the related substory\n",
        "                supporting = map(int, supporting.split())\n",
        "                substory = [story[i - 1] for i in supporting]\n",
        "            else:\n",
        "                # Provide all the substories\n",
        "                substory = [x for x in story if x]\n",
        "            data.append((substory, q, a))\n",
        "            story.append('')\n",
        "        else:\n",
        "            if tokenize:\n",
        "                sent = word_tokenizer(line)\n",
        "            else:\n",
        "                sent = line\n",
        "            story.append(sent)\n",
        "    return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwkiTJYRJvPe"
      },
      "source": [
        "Now we need to take proper structure of the data: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBc_rzF-rKjT"
      },
      "source": [
        "def get_stories(f, only_supporting=False, max_length=None, tokenize=True):\n",
        "    data = parse_stories(f.readlines(), only_supporting=only_supporting, tokenize=tokenize)\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "    data = [(story[0]+story[1], q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FivvTCc8J-GW"
      },
      "source": [
        "Here we need to make the vectors of stories, questions and answers. its too easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzEnmDN_rKjW"
      },
      "source": [
        "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
        "  \n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    ########################################\n",
        "    storyT = list()\n",
        "    queryT = list()\n",
        "    answerT = list()\n",
        "\n",
        "    for story, query, answer in data:\n",
        "        # creating list of story word indices\n",
        "        story1 = [word_idx[w] for w in story]\n",
        "        # creating list of query word indices\n",
        "        query1 = [word_idx[w] for w in query]\n",
        "        # let's not forget that index 0 is reserved\n",
        "        answer1 = np.zeros(len(word_idx) + 1)\n",
        "        # creating label 1 for the answer word index\n",
        "        answer1[word_idx[answer]] = 1\n",
        "        storyT.append(story1)\n",
        "        queryT.append(query1)\n",
        "        answerT.append(answer1)\n",
        "\n",
        "    return (pad_sequences(storyT, maxlen=story_maxlen),\n",
        "            pad_sequences(queryT, maxlen=query_maxlen),\n",
        "            np.array(answerT))\n",
        "\n",
        "\n",
        "    #return inputs_train, queries_train, answers_train\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B77myra2ZJYK"
      },
      "source": [
        "Its time to extract stories from the dataset, then pass them to the defined functions for parsing and make it usable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akcwoo3frKjj"
      },
      "source": [
        "train_stories = get_stories(open(train_file_path), tokenize=True)\n",
        "test_stories = get_stories(open(test_file_path), tokenize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyiMaVRirKjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d97790-39d7-4b7f-a1e5-c15e0e0f10be"
      },
      "source": [
        "len(train_stories), len(test_stories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpXH9iYQrKjq"
      },
      "source": [
        "## 1.3 Check our helper functions and prepare the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29110FTDrKjr"
      },
      "source": [
        "vocab = set()\n",
        "for story, q, answer in train_stories + test_stories:\n",
        "    vocab |= set(story + q + [answer])\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "# Reserve 0 for masking via pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
        "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PopB46hnrKju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae6c2c4-46fc-4c66-c578-ee4e946e3fe3"
      },
      "source": [
        "story_maxlen, query_maxlen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-G22KfxrKjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be04a9eb-fd14-4177-e93a-cd707f99433c"
      },
      "source": [
        "print('-')\n",
        "print('Vocab size:', vocab_size, 'unique words')\n",
        "print('Story max length:', story_maxlen, 'words')\n",
        "print('Query max length:', query_maxlen, 'words')\n",
        "print('Number of training stories:', len(train_stories))\n",
        "print('Number of test stories:', len(test_stories))\n",
        "print('-')\n",
        "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
        "print(train_stories[0])\n",
        "print('-')\n",
        "print('Vectorizing the word sequences...')\n",
        "\n",
        "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
        "idx_word = dict((i+1, c) for i,c in enumerate(vocab))\n",
        "inputs_train, queries_train, answers_train = vectorize_stories(train_stories,\n",
        "                                                               word_idx,\n",
        "                                                               story_maxlen,\n",
        "                                                               query_maxlen)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_stories,\n",
        "                                                            word_idx,\n",
        "                                                            story_maxlen,\n",
        "                                                            query_maxlen)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Vocab size: 22 unique words\n",
            "Story max length: 14 words\n",
            "Query max length: 4 words\n",
            "Number of training stories: 10000\n",
            "Number of test stories: 1000\n",
            "-\n",
            "Here's what a \"story\" tuple looks like (input, query, answer):\n",
            "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'John', 'went', 'to', 'the', 'hallway', '.'], ['Where', 'is', 'Mary', '?'], 'bathroom')\n",
            "-\n",
            "Vectorizing the word sequences...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMnIXlTBrKj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2fb140-e961-4af4-a899-35fcb6010152"
      },
      "source": [
        "inputs_train.shape, queries_train.shape, answers_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 14), (10000, 4), (10000, 22))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4lNOEBkrKj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18098e0f-9e3b-4df1-d80a-af5a1c876032"
      },
      "source": [
        "print('-')\n",
        "print('inputs: integer tensor of shape (samples, max_length)')\n",
        "print('inputs_train shape:', inputs_train.shape)\n",
        "print('inputs_test shape:', inputs_test.shape)\n",
        "print('-')\n",
        "print('queries: integer tensor of shape (samples, max_length)')\n",
        "print('queries_train shape:', queries_train.shape)\n",
        "print('queries_test shape:', queries_test.shape)\n",
        "print('-')\n",
        "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
        "print('answers_train shape:', answers_train.shape)\n",
        "print('answers_test shape:', answers_test.shape)\n",
        "print('-')\n",
        "print('Compiling...')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "inputs: integer tensor of shape (samples, max_length)\n",
            "inputs_train shape: (10000, 14)\n",
            "inputs_test shape: (1000, 14)\n",
            "-\n",
            "queries: integer tensor of shape (samples, max_length)\n",
            "queries_train shape: (10000, 4)\n",
            "queries_test shape: (1000, 4)\n",
            "-\n",
            "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
            "answers_train shape: (10000, 22)\n",
            "answers_test shape: (1000, 22)\n",
            "-\n",
            "Compiling...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvyawLqgfz_N"
      },
      "source": [
        "In this part you should implement 2 functions which illustrate the procedure of learning, Loss and Accuracy. These functions take two inputs: \n",
        "* The history of your designed model \n",
        "* Proper title for describing the plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8Ya5e3e3OWG"
      },
      "source": [
        "def plot_acc(history, title):\n",
        "  \n",
        "  # This function should show not only the plot of accuracy on training and validation set\n",
        "  # but also it should show the maximum value of accuracy with its related epoch.\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.plot(history.history['accuracy'],label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='validation')\n",
        "    plt.legend()\n",
        "    plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history, title):\n",
        "  \n",
        "  # This function should show not only the plot of loss on training and validation set\n",
        "  # but also it should show the minimum value of loss with its related epoch.\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.plot(history.history['loss'],label='train')\n",
        "    plt.plot(history.history['val_loss'], label='validation')\n",
        "    plt.legend()\n",
        "    plt.show() "
      ],
      "metadata": {
        "id": "j_8m7LFBcBmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMxMeM78xBT8"
      },
      "source": [
        "Define model's hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_epochs = 20\n",
        "batch_size = 32\n",
        "lstm_size = 64"
      ],
      "metadata": {
        "id": "oiK700LIcEDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G5X8ksgrKkA"
      },
      "source": [
        "## 1.4 Implementstion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayB5NMoI-Sh-"
      },
      "source": [
        "Let's build the model. You should use Keras framework. The summary and outview of the right model is saved in the next cells to help you create the proper model faster.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UNREQ9rrKkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c892c27-788e-4a36-cb72-d01c58c4b996"
      },
      "source": [
        "# define the model: \n",
        "\n",
        "input_sequence = tf.keras.layers.Input((story_maxlen,))\n",
        "question = tf.keras.layers.Input((query_maxlen,))\n",
        "\n",
        "print('Input sequence:', input_sequence)\n",
        "print('Question:', question)\n",
        "\n",
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "# encoders\n",
        "# embed the input sequence into a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, embedding_dim)\n",
        "\n",
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=query_maxlen))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)\n",
        "\n",
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=query_maxlen))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)\n",
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "# compute a 'match' between the first input vector sequence\n",
        "# and the question vector sequence\n",
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)\n",
        "\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
        "\n",
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "\n",
        "# the original paper uses a matrix multiplication for this reduction step.\n",
        "# we choose to use a RNN instead.\n",
        "answer = LSTM(32)(answer)  # (samples, 32)\n",
        "\n",
        "# one regularization layer -- more would probably be needed.\n",
        "answer = Dropout(0.3)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sequence: KerasTensor(type_spec=TensorSpec(shape=(None, 14), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUvfDiLkrKkF"
      },
      "source": [
        "# build the final model\n",
        "model = tf.keras.models.Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFqPorzN_9Lv"
      },
      "source": [
        "The model architecture should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX6c1qWQ0iMX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4ffc366-d3f4-4ad6-caab-6c33ce6a0333"
      },
      "source": [
        "from IPython.display import SVG\n",
        "\n",
        "SVG(tf.keras.utils.model_to_dot(model,show_shapes= True, show_layer_names=True, dpi=60).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"737pt\" viewBox=\"0.00 0.00 945.00 885.00\" width=\"787pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 881)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-881 941,-881 941,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139982315870928 -->\n<g class=\"node\" id=\"node1\">\n<title>139982315870928</title>\n<polygon fill=\"none\" points=\"164,-830.5 164,-876.5 480,-876.5 480,-830.5 164,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204\" y=\"-861.3\">input_1</text>\n<polyline fill=\"none\" points=\"164,-853.5 244,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204\" y=\"-838.3\">InputLayer</text>\n<polyline fill=\"none\" points=\"244,-830.5 244,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"244,-853.5 302,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"302,-830.5 302,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-849.8\">[(None, 14)]</text>\n<polyline fill=\"none\" points=\"391,-830.5 391,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.5\" y=\"-849.8\">[(None, 14)]</text>\n</g>\n<!-- 139982315872080 -->\n<g class=\"node\" id=\"node3\">\n<title>139982315872080</title>\n<polygon fill=\"none\" points=\"248,-747.5 248,-793.5 598,-793.5 598,-747.5 248,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.5\" y=\"-778.3\">sequential</text>\n<polyline fill=\"none\" points=\"248,-770.5 325,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.5\" y=\"-755.3\">Sequential</text>\n<polyline fill=\"none\" points=\"325,-747.5 325,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"354\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"325,-770.5 383,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"354\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"383,-747.5 383,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431\" y=\"-766.8\">(None, None)</text>\n<polyline fill=\"none\" points=\"479,-747.5 479,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"538.5\" y=\"-766.8\">(None, None, 64)</text>\n</g>\n<!-- 139982315870928&#45;&gt;139982315872080 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139982315870928-&gt;139982315872080</title>\n<path d=\"M350.1341,-830.3799C361.5298,-821.0151 374.8297,-810.0855 386.9245,-800.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"389.1627,-802.8371 394.6665,-793.784 384.7183,-797.429 389.1627,-802.8371\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315899728 -->\n<g class=\"node\" id=\"node7\">\n<title>139982315899728</title>\n<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 354,-710.5 354,-664.5 0,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"44.5\" y=\"-695.3\">sequential_1</text>\n<polyline fill=\"none\" points=\"0,-687.5 89,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"44.5\" y=\"-672.3\">Sequential</text>\n<polyline fill=\"none\" points=\"89,-664.5 89,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"89,-687.5 147,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"147,-664.5 147,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-683.8\">(None, None)</text>\n<polyline fill=\"none\" points=\"243,-664.5 243,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-683.8\">(None, None, 4)</text>\n</g>\n<!-- 139982315870928&#45;&gt;139982315899728 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139982315870928-&gt;139982315899728</title>\n<path d=\"M282.9299,-830.4758C268.0483,-820.4944 251.6448,-807.9036 239,-794 218.8474,-771.8412 202.1942,-742.0674 191.24,-719.6346\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"194.3574,-718.0401 186.9007,-710.5135 188.0363,-721.0474 194.3574,-718.0401\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315784976 -->\n<g class=\"node\" id=\"node2\">\n<title>139982315784976</title>\n<polygon fill=\"none\" points=\"630,-830.5 630,-876.5 930,-876.5 930,-830.5 630,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"670\" y=\"-861.3\">input_2</text>\n<polyline fill=\"none\" points=\"630,-853.5 710,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"670\" y=\"-838.3\">InputLayer</text>\n<polyline fill=\"none\" points=\"710,-830.5 710,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"739\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"710,-853.5 768,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"739\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"768,-830.5 768,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"808.5\" y=\"-849.8\">[(None, 4)]</text>\n<polyline fill=\"none\" points=\"849,-830.5 849,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-849.8\">[(None, 4)]</text>\n</g>\n<!-- 139982315948240 -->\n<g class=\"node\" id=\"node4\">\n<title>139982315948240</title>\n<polygon fill=\"none\" points=\"623,-747.5 623,-793.5 937,-793.5 937,-747.5 623,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"667.5\" y=\"-778.3\">sequential_2</text>\n<polyline fill=\"none\" points=\"623,-770.5 712,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"667.5\" y=\"-755.3\">Sequential</text>\n<polyline fill=\"none\" points=\"712,-747.5 712,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"712,-770.5 770,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"770,-747.5 770,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"806\" y=\"-766.8\">(None, 4)</text>\n<polyline fill=\"none\" points=\"842,-747.5 842,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-766.8\">(None, 4, 64)</text>\n</g>\n<!-- 139982315784976&#45;&gt;139982315948240 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139982315784976-&gt;139982315948240</title>\n<path d=\"M780,-830.3799C780,-822.1745 780,-812.7679 780,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"783.5001,-803.784 780,-793.784 776.5001,-803.784 783.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139982316013264 -->\n<g class=\"node\" id=\"node5\">\n<title>139982316013264</title>\n<polygon fill=\"none\" points=\"372,-664.5 372,-710.5 760,-710.5 760,-664.5 372,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391\" y=\"-695.3\">dot</text>\n<polyline fill=\"none\" points=\"372,-687.5 410,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391\" y=\"-672.3\">Dot</text>\n<polyline fill=\"none\" points=\"410,-664.5 410,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"439\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"410,-687.5 468,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"439\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"468,-664.5 468,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566.5\" y=\"-683.8\">[(None, 14, 64), (None, 4, 64)]</text>\n<polyline fill=\"none\" points=\"665,-664.5 665,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"712.5\" y=\"-683.8\">(None, 14, 4)</text>\n</g>\n<!-- 139982315872080&#45;&gt;139982316013264 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139982315872080-&gt;139982316013264</title>\n<path d=\"M462.8335,-747.3799C479.5826,-737.6583 499.2371,-726.2505 516.8723,-716.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"518.9924,-718.831 525.8842,-710.784 515.4785,-712.7769 518.9924,-718.831\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315948240&#45;&gt;139982316013264 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139982315948240-&gt;139982316013264</title>\n<path d=\"M720.6733,-747.4901C694.1173,-737.1904 662.6368,-724.9806 635.0307,-714.2736\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"636.0311,-710.9076 625.4421,-710.5547 633.4998,-717.4339 636.0311,-710.9076\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315522832 -->\n<g class=\"node\" id=\"node10\">\n<title>139982315522832</title>\n<polygon fill=\"none\" points=\"463,-332.5 463,-378.5 891,-378.5 891,-332.5 463,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506\" y=\"-363.3\">concatenate</text>\n<polyline fill=\"none\" points=\"463,-355.5 549,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506\" y=\"-340.3\">Concatenate</text>\n<polyline fill=\"none\" points=\"549,-332.5 549,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"578\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"549,-355.5 607,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"578\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"607,-332.5 607,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"701.5\" y=\"-351.8\">[(None, 4, 14), (None, 4, 64)]</text>\n<polyline fill=\"none\" points=\"796,-332.5 796,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"843.5\" y=\"-351.8\">(None, 4, 78)</text>\n</g>\n<!-- 139982315948240&#45;&gt;139982315522832 -->\n<g class=\"edge\" id=\"edge11\">\n<title>139982315948240-&gt;139982315522832</title>\n<path d=\"M781.8153,-747.4221C784.1757,-715.3746 788,-655.5696 788,-604.5 788,-604.5 788,-604.5 788,-521.5 788,-471.2439 778.9887,-456.0528 750,-415 742.1088,-403.8248 731.5777,-393.5985 720.9753,-384.8947\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"722.9213,-381.9725 712.8962,-378.545 718.5958,-387.4762 722.9213,-381.9725\" stroke=\"#000000\"/>\n</g>\n<!-- 139982316007696 -->\n<g class=\"node\" id=\"node6\">\n<title>139982316007696</title>\n<polygon fill=\"none\" points=\"403.5,-581.5 403.5,-627.5 728.5,-627.5 728.5,-581.5 403.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"442\" y=\"-612.3\">activation</text>\n<polyline fill=\"none\" points=\"403.5,-604.5 480.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"442\" y=\"-589.3\">Activation</text>\n<polyline fill=\"none\" points=\"480.5,-581.5 480.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"509.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"480.5,-604.5 538.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"509.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"538.5,-581.5 538.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"586\" y=\"-600.8\">(None, 14, 4)</text>\n<polyline fill=\"none\" points=\"633.5,-581.5 633.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"681\" y=\"-600.8\">(None, 14, 4)</text>\n</g>\n<!-- 139982316013264&#45;&gt;139982316007696 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139982316013264-&gt;139982316007696</title>\n<path d=\"M566,-664.3799C566,-656.1745 566,-646.7679 566,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"569.5001,-637.784 566,-627.784 562.5001,-637.784 569.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315545104 -->\n<g class=\"node\" id=\"node8\">\n<title>139982315545104</title>\n<polygon fill=\"none\" points=\"374,-498.5 374,-544.5 758,-544.5 758,-498.5 374,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-529.3\">add</text>\n<polyline fill=\"none\" points=\"374,-521.5 416,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-506.3\">Add</text>\n<polyline fill=\"none\" points=\"416,-498.5 416,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"416,-521.5 474,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"474,-498.5 474,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"568.5\" y=\"-517.8\">[(None, 14, 4), (None, 14, 4)]</text>\n<polyline fill=\"none\" points=\"663,-498.5 663,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710.5\" y=\"-517.8\">(None, 14, 4)</text>\n</g>\n<!-- 139982316007696&#45;&gt;139982315545104 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139982316007696-&gt;139982315545104</title>\n<path d=\"M566,-581.3799C566,-573.1745 566,-563.7679 566,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"569.5001,-554.784 566,-544.784 562.5001,-554.784 569.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315899728&#45;&gt;139982315545104 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139982315899728-&gt;139982315545104</title>\n<path d=\"M220.5474,-664.3073C264.0522,-641.5969 333.1737,-606.75 395,-581 423.6771,-569.0562 455.6974,-557.4668 484.2057,-547.738\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"485.3807,-551.0355 493.7292,-544.5122 483.1349,-544.4055 485.3807,-551.0355\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315550480 -->\n<g class=\"node\" id=\"node9\">\n<title>139982315550480</title>\n<polygon fill=\"none\" points=\"429,-415.5 429,-461.5 741,-461.5 741,-415.5 429,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-446.3\">permute</text>\n<polyline fill=\"none\" points=\"429,-438.5 493,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-423.3\">Permute</text>\n<polyline fill=\"none\" points=\"493,-415.5 493,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"522\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"493,-438.5 551,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"522\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"551,-415.5 551,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598.5\" y=\"-434.8\">(None, 14, 4)</text>\n<polyline fill=\"none\" points=\"646,-415.5 646,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"693.5\" y=\"-434.8\">(None, 4, 14)</text>\n</g>\n<!-- 139982315545104&#45;&gt;139982315550480 -->\n<g class=\"edge\" id=\"edge9\">\n<title>139982315545104-&gt;139982315550480</title>\n<path d=\"M571.2926,-498.3799C573.1913,-490.0854 575.3711,-480.5633 577.4254,-471.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"580.8502,-472.3129 579.6699,-461.784 574.0267,-470.7508 580.8502,-472.3129\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315550480&#45;&gt;139982315522832 -->\n<g class=\"edge\" id=\"edge10\">\n<title>139982315550480-&gt;139982315522832</title>\n<path d=\"M610.6271,-415.3799C620.8096,-406.1935 632.6612,-395.5013 643.5085,-385.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"646.1108,-388.0813 651.1912,-378.784 641.4218,-382.8839 646.1108,-388.0813\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315904528 -->\n<g class=\"node\" id=\"node11\">\n<title>139982315904528</title>\n<polygon fill=\"none\" points=\"532.5,-249.5 532.5,-295.5 821.5,-295.5 821.5,-249.5 532.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560.5\" y=\"-280.3\">lstm</text>\n<polyline fill=\"none\" points=\"532.5,-272.5 588.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560.5\" y=\"-257.3\">LSTM</text>\n<polyline fill=\"none\" points=\"588.5,-249.5 588.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"617.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"588.5,-272.5 646.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"617.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"646.5,-249.5 646.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"694\" y=\"-268.8\">(None, 4, 78)</text>\n<polyline fill=\"none\" points=\"741.5,-249.5 741.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"781.5\" y=\"-268.8\">(None, 32)</text>\n</g>\n<!-- 139982315522832&#45;&gt;139982315904528 -->\n<g class=\"edge\" id=\"edge12\">\n<title>139982315522832-&gt;139982315904528</title>\n<path d=\"M677,-332.3799C677,-324.1745 677,-314.7679 677,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"680.5001,-305.784 677,-295.784 673.5001,-305.784 680.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315903312 -->\n<g class=\"node\" id=\"node12\">\n<title>139982315903312</title>\n<polygon fill=\"none\" points=\"529.5,-166.5 529.5,-212.5 824.5,-212.5 824.5,-166.5 529.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"568\" y=\"-197.3\">dropout_3</text>\n<polyline fill=\"none\" points=\"529.5,-189.5 606.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"568\" y=\"-174.3\">Dropout</text>\n<polyline fill=\"none\" points=\"606.5,-166.5 606.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"635.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"606.5,-189.5 664.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"635.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"664.5,-166.5 664.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704.5\" y=\"-185.8\">(None, 32)</text>\n<polyline fill=\"none\" points=\"744.5,-166.5 744.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"784.5\" y=\"-185.8\">(None, 32)</text>\n</g>\n<!-- 139982315904528&#45;&gt;139982315903312 -->\n<g class=\"edge\" id=\"edge13\">\n<title>139982315904528-&gt;139982315903312</title>\n<path d=\"M677,-249.3799C677,-241.1745 677,-231.7679 677,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"680.5001,-222.784 677,-212.784 673.5001,-222.784 680.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315546512 -->\n<g class=\"node\" id=\"node13\">\n<title>139982315546512</title>\n<polygon fill=\"none\" points=\"542,-83.5 542,-129.5 812,-129.5 812,-83.5 542,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"568\" y=\"-114.3\">dense</text>\n<polyline fill=\"none\" points=\"542,-106.5 594,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"568\" y=\"-91.3\">Dense</text>\n<polyline fill=\"none\" points=\"594,-83.5 594,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"594,-106.5 652,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"652,-83.5 652,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"692\" y=\"-102.8\">(None, 32)</text>\n<polyline fill=\"none\" points=\"732,-83.5 732,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"772\" y=\"-102.8\">(None, 22)</text>\n</g>\n<!-- 139982315903312&#45;&gt;139982315546512 -->\n<g class=\"edge\" id=\"edge14\">\n<title>139982315903312-&gt;139982315546512</title>\n<path d=\"M677,-166.3799C677,-158.1745 677,-148.7679 677,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"680.5001,-139.784 677,-129.784 673.5001,-139.784 680.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139982315315344 -->\n<g class=\"node\" id=\"node14\">\n<title>139982315315344</title>\n<polygon fill=\"none\" points=\"524.5,-.5 524.5,-46.5 829.5,-46.5 829.5,-.5 524.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"568\" y=\"-31.3\">activation_1</text>\n<polyline fill=\"none\" points=\"524.5,-23.5 611.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"568\" y=\"-8.3\">Activation</text>\n<polyline fill=\"none\" points=\"611.5,-.5 611.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"640.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"611.5,-23.5 669.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"640.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"669.5,-.5 669.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"709.5\" y=\"-19.8\">(None, 22)</text>\n<polyline fill=\"none\" points=\"749.5,-.5 749.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789.5\" y=\"-19.8\">(None, 22)</text>\n</g>\n<!-- 139982315546512&#45;&gt;139982315315344 -->\n<g class=\"edge\" id=\"edge15\">\n<title>139982315546512-&gt;139982315315344</title>\n<path d=\"M677,-83.3799C677,-75.1745 677,-65.7679 677,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"680.5001,-56.784 677,-46.784 673.5001,-56.784 680.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxK-MxYMrKkI"
      },
      "source": [
        "Model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjEgTL9LrKkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28270f15-e6d0-476c-a6a0-e47ed8571b03"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 14)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, None, 64)     1408        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 4, 64)        1408        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 14, 4)        0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 14, 4)        0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 4)      88          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 14, 4)        0           ['activation[0][0]',             \n",
            "                                                                  'sequential_1[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 4, 14)        0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4, 78)        0           ['permute[0][0]',                \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           14208       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 22)           726         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 22)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,838\n",
            "Trainable params: 17,838\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tnbz5YJrKkQ"
      },
      "source": [
        "## 1.5 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_bUUHq-A8Us"
      },
      "source": [
        "In this section we start the training procedure with fitting the data to the designed model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([inputs_train, queries_train], answers_train, batch_size, train_epochs,\n",
        "          validation_data=([inputs_test, queries_test], answers_test))\n",
        "\n",
        "plot_loss(history,\"Loss\")\n",
        "plot_acc(history,\"Accuracy\")\n",
        "\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "c3sOGkotZKmk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dab0b95a-e859-4101-e414-76bd83afb17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "  3/313 [..............................] - ETA: 12s - loss: 1.7391 - accuracy: 0.2708"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 13s 41ms/step - loss: 1.7624 - accuracy: 0.2407 - val_loss: 1.7490 - val_accuracy: 0.2830\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 1.7622 - accuracy: 0.2441 - val_loss: 1.7514 - val_accuracy: 0.2820\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 1.7605 - accuracy: 0.2520 - val_loss: 1.7465 - val_accuracy: 0.2820\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 1.7577 - accuracy: 0.2532 - val_loss: 1.7465 - val_accuracy: 0.2850\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 1.7588 - accuracy: 0.2546 - val_loss: 1.7388 - val_accuracy: 0.2900\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 1.7567 - accuracy: 0.2611 - val_loss: 1.7372 - val_accuracy: 0.2990\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 1.7554 - accuracy: 0.2622 - val_loss: 1.7351 - val_accuracy: 0.2980\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 1.7501 - accuracy: 0.2667 - val_loss: 1.7501 - val_accuracy: 0.2730\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 1.7489 - accuracy: 0.2641 - val_loss: 1.7342 - val_accuracy: 0.2980\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 1.7455 - accuracy: 0.2706 - val_loss: 1.7268 - val_accuracy: 0.3100\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 1.7465 - accuracy: 0.2691 - val_loss: 1.7291 - val_accuracy: 0.3120\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 1.7474 - accuracy: 0.2692 - val_loss: 1.7273 - val_accuracy: 0.3040\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 1.7427 - accuracy: 0.2725 - val_loss: 1.7250 - val_accuracy: 0.3160\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 1.7420 - accuracy: 0.2739 - val_loss: 1.7266 - val_accuracy: 0.3120\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 1.7439 - accuracy: 0.2766 - val_loss: 1.7279 - val_accuracy: 0.3090\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 1.7417 - accuracy: 0.2745 - val_loss: 1.7295 - val_accuracy: 0.3110\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 1.7395 - accuracy: 0.2738 - val_loss: 1.7277 - val_accuracy: 0.3100\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 1.7378 - accuracy: 0.2784 - val_loss: 1.7257 - val_accuracy: 0.3120\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 1.7387 - accuracy: 0.2830 - val_loss: 1.7243 - val_accuracy: 0.3140\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 1.7353 - accuracy: 0.2798 - val_loss: 1.7269 - val_accuracy: 0.3110\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXxhXOvcrKkV"
      },
      "source": [
        "## 1.6 Testing and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciBt077dEBLd"
      },
      "source": [
        "Now we need to actually make predictions and check the performance of our trained model with some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4b3f5-arKkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aff5358-e6b6-4918-ec53-706e660ae441"
      },
      "source": [
        "for i in range(0,10):\n",
        "    current_inp = test_stories[2*i]\n",
        "    current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
        "    current_prediction = model.predict([current_story, current_query])\n",
        "    current_prediction = idx_word[np.argmax(current_prediction)]\n",
        "    print(' '.join(current_inp[0]), ' '.join(current_inp[1]), '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is John ? | Prediction: bathroom | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is Sandra ? | Prediction: bathroom | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is Sandra ? | Prediction: bathroom | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Where is Sandra ? | Prediction: hallway | Ground Truth: garden\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Where is Sandra ? | Prediction: hallway | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Mary ? | Prediction: kitchen | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Daniel ? | Prediction: bathroom | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Mary ? | Prediction: kitchen | Ground Truth: bedroom\n",
            "-----------------------------------------------------------------------------------------\n",
            "John moved to the hallway . John journeyed to the kitchen . Where is John ? | Prediction: kitchen | Ground Truth: garden\n",
            "-----------------------------------------------------------------------------------------\n",
            "John moved to the hallway . John journeyed to the kitchen . Where is Daniel ? | Prediction: kitchen | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "DWGbl4PdrKka"
      },
      "source": [
        "## 1.7 Custom Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJUI2SIXEV4x"
      },
      "source": [
        "You can even write your example and test it with your model to see how powerful it is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT83MJ8yrKkb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "outputId": "a87804ac-8dca-4800-d96e-4671e805e6fe"
      },
      "source": [
        "print('-------------------------------------------------------------------------------------------')\n",
        "print('Custom User Queries (Make sure there are spaces before each word)')\n",
        "while 1:\n",
        "    print('-------------------------------------------------------------------------------------------')\n",
        "    print('Please input a story')\n",
        "    user_story_inp = input().split(' ')\n",
        "    print('Please input a query')\n",
        "    user_query_inp = input().split(' ')\n",
        "    user_story, user_query, user_ans = vectorize_stories([[user_story_inp, user_query_inp, '.']], word_idx, story_maxlen, query_maxlen)\n",
        "    user_prediction = model.predict([user_story, user_query])\n",
        "    user_prediction = idx_word[np.argmax(user_prediction)]\n",
        "    print('Result')\n",
        "    print(' '.join(user_story_inp), ' '.join(user_query_inp), '| Prediction:', user_prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------------------------\n",
            "Custom User Queries (Make sure there are spaces before each word)\n",
            "-------------------------------------------------------------------------------------------\n",
            "Please input a story\n",
            "Mary went to the bathroom . John moved to the hallway . Mary travelled to the office .\n",
            "Please input a query\n",
            "Where is Mary ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result\n",
            "Mary went to the bathroom . John moved to the hallway . Mary travelled to the office . Where is Mary ? | Prediction: office\n",
            "-------------------------------------------------------------------------------------------\n",
            "Please input a story\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \"\"\"\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-cd5b1d8fbfdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------------------------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please input a story'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0muser_story_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please input a query'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0muser_query_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id1unEEQrKkf"
      },
      "source": [
        "# some examples:\n",
        "# Mary went to the bathroom . John moved to the hallway . Mary travelled to the office . # Where is Mary ?\n",
        "# Sandra travelled to the office . John journeyed to the garden ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtYRcM2KE4te"
      },
      "source": [
        "As you understood how the model trained, please tell us about the pros and cons of the proposed model. How can we improve it if we want to use it in realistic task ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9NiIbN5F7zb"
      },
      "source": [
        "$\\color{red}{\\text{Write your answer in document}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer : **\n",
        "مشخصا مدل آموزش داده شده توانایی هندل کردن دنباله های طولانی را ندارد ، استفاده از lstm ها می تواند کمک کننده باشد.\n"
      ],
      "metadata": {
        "id": "n3ptWqezThnJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFKXfqrgQfQm"
      },
      "source": [
        "#  2. Hands on Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7UbcqmKUZ1q"
      },
      "source": [
        "## 2.1 Preprocessing\n",
        "\n",
        "We will use dataset from tfds api in this sections. These datasets are prepared in [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) format which can be used in a pipeline to read data and do the needed preprocessings on that. But for our purpos we can't use pipeline functions to achieve our goal so we will exctract dataset from Dataset format and later we will convert it back."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "(train_data, validation_data), ds_info = tfds.load('imdb_reviews', \n",
        "          split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "          as_supervised=True,\n",
        "          with_info=True)\n",
        "print('info', ds_info)"
      ],
      "metadata": {
        "id": "RDOwLbCAjENO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f8c65f-d38f-4768-dbd4-81fa9a5afe27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "info tfds.core.DatasetInfo(\n",
            "    name='imdb_reviews',\n",
            "    version=1.0.0,\n",
            "    description='Large Movie Review Dataset.\n",
            "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
            "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
            "    features=FeaturesDict({\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "        'text': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    total_num_examples=100000,\n",
            "    splits={\n",
            "        'test': 25000,\n",
            "        'train': 25000,\n",
            "        'unsupervised': 50000,\n",
            "    },\n",
            "    supervised_keys=('text', 'label'),\n",
            "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "      month     = {June},\n",
            "      year      = {2011},\n",
            "      address   = {Portland, Oregon, USA},\n",
            "      publisher = {Association for Computational Linguistics},\n",
            "      pages     = {142--150},\n",
            "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Tokenization\n",
        "There are 3 important parts to prepare the transformer model for training and inference: Tokenizer, Confing and the Model itself.\n",
        "\n",
        "Tokenizer as it's clear from its name is a tool to convert input string to tokens and assign an id to each one so it can be passed to model input. Tokenizer is trained prior to training the main model using [sentence piece](https://github.com/google/sentencepiece) library.\n",
        "\n",
        "There are two important things to consider with tokenization:\n",
        "1. As part of transformer models there are special tokens that should be added to input string before passing it to model. These tokens are in the tokenizer class.\n",
        "2. Alongside the the ids of input string there are two other inputs witch each sample: Attention Mask, Token Type IDs. Feel free to google these terms to find out more.\n"
      ],
      "metadata": {
        "id": "Fl9UenUrU8H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "_GMQmFwajGW4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_test = 20\n",
        "test_sentence = \"This film is awsome you should watch it\"\n",
        "\n",
        "# add special tokens\n",
        "test_sentence_with_special_tokens = '[CLS]' + test_sentence + '[SEP]'\n",
        "tokenized = tokenizer.tokenize(test_sentence_with_special_tokens)\n",
        "print('tokenized', tokenized)\n",
        "\n",
        "\n",
        "# convert tokens to ids\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
        "\n",
        "# precalculation of pad length, so that we can reuse it later on\n",
        "padding_length = max_length_test - len(input_ids)\n",
        "# map tokens to WordPiece dictionary and add pad token for those text shorter than our max length\n",
        "input_ids = input_ids + ([0] * padding_length)\n",
        "\n",
        "# attention should focus just on sequence with non padded tokens\n",
        "attention_mask = [1] * len(input_ids)\n",
        "# do not focus attention on padded tokens\n",
        "attention_mask = attention_mask + ([0] * padding_length)\n",
        "\n",
        "# token types, needed for example for question answering, for our purpose we will just set 0 as we have just one sequence\n",
        "token_type_ids = [0] * max_length_test\n",
        "\n",
        "bert_input = {\n",
        "    \"token_ids\": input_ids,\n",
        "    \"token_type_ids\": token_type_ids,\n",
        "    \"attention_mask\": attention_mask\n",
        "} \n",
        "print(bert_input)"
      ],
      "metadata": {
        "id": "cBwOJ5sJjJOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74735b02-ed83-417d-96aa-38e367be8f01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenized ['[CLS]', 'this', 'film', 'is', 'aw', '##some', 'you', 'should', 'watch', 'it', '[SEP]']\n",
            "{'token_ids': [101, 2023, 2143, 2003, 22091, 14045, 2017, 2323, 3422, 2009, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do all the above operations to prepare each input or we can use encode_plus function which does the boilerpolate code. Use encode_plus to get output like above for test sentence."
      ],
      "metadata": {
        "id": "wOlkbozHVMz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_input = tokenizer.encode_plus( # same as calling tokenizer itself e.g tokenizer(....)\n",
        "                        test_sentence,                      \n",
        "                        add_special_tokens = True, # add [CLS], [SEP]\n",
        "                        max_length = max_length_test, # max length of the text that can go to BERT\n",
        "                        padding='max_length', # add [PAD] tokens\n",
        "                        return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "              )\n",
        "print(bert_input)"
      ],
      "metadata": {
        "id": "B4R5nnKejLF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7a66fa-61f8-4d73-93e3-bd5ebaa88096"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 2023, 2143, 2003, 22091, 14045, 2017, 2323, 3422, 2009, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should convert each sample to above format. To do this we will iterate overt dataset and convert each sample. We will put converted samples in tf.data.Dataset format. We will also apply a [map function](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) on dataset to convert it to dictionary format. We don't need token type ids as we have one token type in this task. Complete the functions below."
      ],
      "metadata": {
        "id": "4hu0WKFGVSPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def map_example_to_dict(input_ids, attention_mask, label):\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        #\"token_type_ids\": token_type_ids,\n",
        "        \"attention_mask\": attention_mask\n",
        "    }, label\n",
        "\n",
        "\n",
        "def encode_examples(ds, max_sequence_length):\n",
        "    # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
        "    input_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    labels = []\n",
        "   # token_type_ids_list = []\n",
        "\n",
        "    if (max_sequence_length > 0):\n",
        "      ds = ds.take(max_sequence_length)\n",
        "\n",
        "    for review, label in tfds.as_numpy(ds):\n",
        "      bert_input= tokenizer.encode_plus(review.decode(), \n",
        "                add_special_tokens = True, # add [CLS], [SEP]\n",
        "                max_length = max_sequence_length, # max length of the text that can go to BERT\n",
        "                pad_to_max_length = True, # add [PAD] tokens\n",
        "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "              )\n",
        "      #bert_input = convert_example_to_feature(review.decode())\n",
        "      input_ids_list.append(bert_input['input_ids'])\n",
        "      #token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "      attention_mask_list.append(bert_input['attention_mask'])\n",
        "      labels.append([label])\n",
        "\n",
        "\n",
        "    #iterate over ds and extract input ids and attention masks for each sample\n",
        "\n",
        "    # reshape each input_ids_list and attention_mask_list to (-1, max_sequence_length)\n",
        "    # reshape labels to (-1, 1)\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, labels)).map(map_example_to_dict)"
      ],
      "metadata": {
        "id": "6qNEkwHGVRHu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataset\n",
        "batch_size = 8\n",
        "max_sequence_length = 256 # can be up to 512 for BERT but I have resourse Eroor in colab\n",
        "\n",
        "train_data_encoded = encode_examples(train_data, max_sequence_length).batch(batch_size)\n",
        "validation_data_encoded = encode_examples(validation_data.take(5000), max_sequence_length).batch(batch_size)\n",
        "\n",
        "print(train_data_encoded)\n",
        "print(validation_data_encoded)"
      ],
      "metadata": {
        "id": "kX0D5NkDT_0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce21ffdc-903e-4765-c39f-913206b6f4b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 256), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))>\n",
            "<BatchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 256), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Defining model"
      ],
      "metadata": {
        "id": "65sDlwQKVwau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "########################################\n",
        "#     Put your implementation here    #\n",
        "########################################\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "4SbjrcMhdmaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da3e234-66d8-4ad7-c8c0-a167b93833fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "_q3o-T6jdp9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fa8b84-a7b5-4408-d44d-528b7896c8b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  109482240 \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  1538      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Training"
      ],
      "metadata": {
        "id": "SfbuR4ygWDTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "########################################\n",
        "#     Put your implementation here     # best accuracy: 96.88 % in epoch=5\n",
        "########################################\n",
        "model.compile(optimizer= tf.keras.optimizers.Adam(2e-5),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data_encoded, validation_data=validation_data_encoded, epochs=epochs)"
      ],
      "metadata": {
        "id": "eKQ34LdHdtB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ad8000-3844-4d24-e7c2-155cb306df74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 23s 700ms/step - loss: 0.6846 - accuracy: 0.5664 - val_loss: 0.6282 - val_accuracy: 0.6992\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 23s 711ms/step - loss: 0.4451 - accuracy: 0.8438 - val_loss: 0.4396 - val_accuracy: 0.8008\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 23s 716ms/step - loss: 0.2501 - accuracy: 0.9141 - val_loss: 0.6360 - val_accuracy: 0.7422\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 22s 706ms/step - loss: 0.1896 - accuracy: 0.9336 - val_loss: 0.5446 - val_accuracy: 0.7773\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 23s 717ms/step - loss: 0.1251 - accuracy: 0.9648 - val_loss: 0.4108 - val_accuracy: 0.8320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faeeb6b2110>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Testing\n",
        "Feel free to change these senetences and test the model."
      ],
      "metadata": {
        "id": "cxdxFFOhV-7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_sentences = [\"This is an awful film do not watch it.\", \"This is an aswsome film you should watch it.\"]"
      ],
      "metadata": {
        "id": "MD7NUrNdd_5Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# testing pred_sentences[i]\n",
        "tf_batch = tokenizer(pred_sentences, max_length=128, add_special_tokens = True, padding=True, truncation=True, return_tensors='tf')\n",
        "tf_outputs = model(tf_batch)\n",
        "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
        "labels = ['Negative','Positive']\n",
        "\n",
        "########################################\n",
        "#     Put your implementation here    #\n",
        "########################################\n",
        "label = tf.argmax(tf_predictions, axis=1).numpy()\n",
        "for i in range(len(pred_sentences)):\n",
        "    print(pred_sentences[i], \": \", labels[label[i]])"
      ],
      "metadata": {
        "id": "zjpMj7qLeu84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f04aeba-f57e-4928-d093-00460972c4ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an awful film do not watch it. :  Negative\n",
            "This is an aswsome film you should watch it. :  Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an awful film do not watch it. : \n",
        "\n",
        " Negative\n",
        " \n",
        "This is an aswsome film you should watch it. : \n",
        "\n",
        " Positive"
      ],
      "metadata": {
        "id": "OuWpvUAQeIEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\color{red}{\\text{Write your answer in document}}$\n",
        "\n",
        "1. When token type ids is useful?\n",
        "2. What is the main idea of transformer models? Explain it.\n",
        "3. What can be challenges to transformers if input sequences are very long? Why?"
      ],
      "metadata": {
        "id": "A1dJst5HWSF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT: for further study (It has no grade)\n",
        "\n",
        "The task is to train poem based on GPT-2 model which is available in transformers library. You will choose poets of Shakespeare and train GPT-2 on that dataset and produce some sample poets.\n",
        "\n",
        "Solution link: http://education.abcom.com/using-gpt-2-to-write-like-shakespeare/\n",
        "\n"
      ],
      "metadata": {
        "id": "QNjXfQ5kWd7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtHWzkJ6WL29",
        "outputId": "05c34457-f497-42c5-fa55-d7188717d49f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HYpcurVWi62",
        "outputId": "4c606a64-86d0-4e40-a179-64c5d61029e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun  9 07:36:09 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    31W /  70W |   8624MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtmazEJDWkkc",
        "outputId": "1138842f-bdcd-4220-aee8-41c2012819fb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-09 07:36:09--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.005s  \n",
            "\n",
            "2022-06-09 07:36:10 (207 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading GPT-2\n",
        "\n",
        "########################################\n",
        "#   Put your implementation here    #\n",
        "########################################"
      ],
      "metadata": {
        "id": "2k4R7ZAPWmJF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune GPT-2\n",
        "\n",
        "########################################\n",
        "#   Put your implementation here     #\n",
        "########################################"
      ],
      "metadata": {
        "id": "Sw-WTqQ2ZpOO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_oIfSFCIZuQ2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Text From The Trained Model\n",
        "\n",
        "########################################\n",
        "#   Put your implementation here     #\n",
        "########################################"
      ],
      "metadata": {
        "id": "wG9OI0_WZuDO"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}